
============== READING COMPONENTS FROM A WORKING OR A BUILTIN
               DIRECTORY ====================================

= In the java implementation, custom components (built by the user, user-defined) were read, as encountered in the HDL specification, from whatever is recorded as the current working directory (often this is the directory from which either the test script, or the program file, is loaded from).

= In the web app, what is the working directory? ... There is no such thing. Maybe local storage: put all components into local storage as soon as they are uploaded. Actually, there is no other option if the components are not known ahead of time. In the long run, these component specifications can be uploaded into some central repository, or into a database that is allocated to a specific customer, or user. The repository, or the database, could also be potentially where the builtin component specifications will be stored, like the npm repository, remember?

= So when trying to decide between a builtin and a user-defined component, first look for the component in the local storage (in case the user has uploaded one). Which also mean that the user would have to upload all the required components (the entire directory of components), or all his components (especially if he desires for his custom components to be used instead of the builtin versions), into local storage.

= And wherever the java implementations fetches content by reading a file, provide a similar content either from local storage or from an imported json file, or from a database/repository, or from whatever source seems appropriate, and fitting, to the situation at hand.

=============== INTERACTING WITH USER INTERFACE FROM
                ANY CLASS ==========================

= In the java implementation, any code from any class can update a GUI, as long as it holds a reference to it. Can we do the same thing in the web app?

= Of course, in the web app context as well, any code from anywhere can manipulate the dom anyway it wants to. So, there should be no reason why this can't be possible in react as well. One pattern with react is that it decouples code for the user interface and code for business logic. Business logic code can simply update the state, and the UI change will follow from the change in the component's state.

= So wherever calls to UI component's are made from within a business logic in java, a corresponding state update call should be made from within react. That means you would have to not only know what state change to make to produce a similar effect, but also have to know to properly apply it wherever it is needed.

= Do we have any other option? Maybe. We can simply ignore the UI manipulation calls, and focus on getting the business logic right. Then test the business logic independently, and afterwards, move on to integrating the react UI comoponent with the business logic.

= There is still another option. Mock the java UI classes, and maybe do just a console log within these mocked methods. This can however get nasty later on, if we try to mock every method of some swing component. But if the nastiness is moderate, the state update calls then can be made from within these mocked methods. And the mock classes will serve as the glue between the business logic and the react UI component.

= In local storage a gate might be represented with a json like this:
{
  "name": "Mux",
  "hdl": "blah blah"
}

= How about the assembler? Imitate their assembler or develop one from sccratch? Their assembler might have additional features, such as parsing a compare, and or a test file, and running a comparison against it. Will these features ( a compare file, and test files) be relevant in the light of the bigger picture? I mean testing is an integral part of a sustainable development, so yeah, they will definitely be needed.

= The java implementations of the translators are also interlinked with the GUI that controls their actions. When turning these into web apps, we will have to find some mechanism (say marshalling callbacks, or state values) to achieve a similar interaction.

= What do we do when the java implementation extends native java classes, or interfaces?
  -> Mock their interfaces by providing an equivalent service.

= What is the equivalent of a java Thread in typescript? Javascript is normally single threaded, unless something like a web worker is used. Well they are called worker threads, they run off a javascript file (or url path) containing a function. You can exchange messages with them ... so if the need really comes to it, you can spawn a couple of them worker threads.

= Now back to the assembler. How do we run it? I mean from its java code ... how do you feed it the assembly file? ... I like it when it is used on the fly by the CPU emulator.
  --- Hehe and we have finally extracted and tested the module that is responsible for the on-the-fly translation done by the cpu emulator.

|||||||||||| NOW THAT WE HAVE AN ASSEMBLER THAT CAN CONVERT OUR ASSEMBLY CODE TO MACHINE CODE
= There are two possible next steps: Either go up and build a compiler that translates a high level language code into an assembly code, or go down and build a simulator that can run the translated machine code by simulating the underlying hardware (which can be done by reading it either from an hdl file or by employing builtin hardware definitions). The later options promises more exciting and interesting, and henece, we shall get started with it at once.

= So the GUI of the hardware simulator seems divided into two main sections: the controller and the simulator. The controller gui, as its name suggests, is concerned with controlling the simulation, like setting it up, configuring it, tweaking it, and modifying it. The simulation gui on the other hand deals with displaying the dynamic evolution of the data processing that is being simulated.

= How do I test the hardware simulator? Well, by giving it an HDL design of the hardware, and then by providing it with a test script that commands the hardware to do certain things, and then by comparing the hardware outputs with expected outcomes listed in a compare file.

= For the time being, I don't need none of the fancy simulator or controller displays. I will just put the test script, the hdl, and the compare file in local storage, and all I want is a console.log that communicates either error or success, as the case might be.

= The class <HackController> is the glue that binds the simulator and controller components. So start your development from it.

= You can implement the <HardwareSimulatorComponent> by leaving out the implementation details of the interface methods, you can leave them either with an empty body or can do a simple console log of the operation, and likewise the <HardwareSimulatorControllerComponent>.

= So, from which end would you like to start?  From the component's end or from the interface's end? Last time, with the assembler, I got started from the interface's end, let's this time get started from the component's end (the UI's end) and see where it will lead me, or so see whether starting from the UI end will prove rewarding or not.

= I am just saying, you have to try it. A perfect and direct mapping between a java swing application and a react app. Why can't swing components be directly mapped into react components? What is the catch? You should go for it, and stop when you get stuck. But for now, focus on getting the functionality right (by manually calling what would have been invoked following a button click).

-----------------------------------------------

= Do I really need to build a symbol table? The symbol table is used to map function and label names to addresses, but why would I need an address? And is not after all, the symbol table built by the assembler, I don't think there is a need for doing it here, so just get rid off it.
Or, in case it comes handy later on, for some weird reason, you can just let it sit there, you can let it be.


=====================================
WHILE IMPLEMENTING THE VM TRANSLATOR 
-------------------------------------

>>> If there is at least one funciton in the vm program, there would have to be a sys.init that calls it. But if there is no sys.init, while there is a function, you should add the body of sys.init with a call to the function ... The book says it is the compilers' job to ensure that there is at least one such function sys.init .

---- |||| let's investigate them vm programs, and see if they are translatable ... huh?

===>>> make sure sp is incremented after every push operation, and that it is decremented
after every pop operation, (it is also decremented before accessing top of the stack value,
but decrement not the SP, but simply use the decremented value).

====================================
COMPILING II, CODE GENERATION
------------------------------------
>>> The tokenizer, and the compilation engine, worked on one jack class at a time. This is going to continue in the code generation step (still going to process a single class at a time). It is the vm translator that later assembles all the separate vm files together.
>>> I am assuming I will need one symbol table instance per jack class. The symbol table is simply going to help me track the variables (their characterstics, and state info). 
>>> How is identifier resolution to be made when an identifier of the same name is found in nested scopes. As far as I am concerned now, all I need is two table scopes, the current subroutine table scope, and the current class table scope. If an extera table scope is necessary, it shall be seen (I shall find out later when stuck).

>>> identifier Info:
  = category: comes either from the symbol table (when not currently being defined) or from inspecting the preceding keyword of the current token (when being defined for the first time, it shall be deducted from the context, eg: is it varDec, letStatement, paramDec .... ?).
  = Is it being defined? YES (if part of the var statement, or if it is undefined following a symbol table look up), NO otherwise.
  = Is it one of the four? (this can be inferred from the surrounding context, or from a symbol table lookup; subroutine and class names are for instance not in the symbol table)
  = Running index: this is found from the symbol table ....

  THE THREE IDEAS 
  ===============

  >>> A web app that interactively probes, and demystifies, all the salient hardware and software abstractions of a running virtual computer.
  ------------------------------------------------------

  Computer science and software engineering courses are, as given now, not well structured to provide students with a clear and comprhensive understanding of what a computer really is, and what essential concepts/theories it entails. Some courses are cluttered with too much detail, while others scratch only the surface. And there is no clear progression from one course to the next. Hence computer science and software engineering students often graduate without forming a lucid picture of the components that make up a computer, the interactions that take place between these components, and the underlying principles and abstractions that in turn make the interactions possible.

  In this project, we aim to build a web app that visually and interactively illustrates the salient interactions and abstractions that a high level program (operation) passes through till it is turned into a machine code (of zeros and ones) that is channeled through an architecture made up of just nand gates and flip-flops. The interactive animation will be built on top of a simplifed virtual computer (as specified in the book 'The elements of computing systems from first principles') that will be running alongside the visual animations and displays.

  With the guidance of the aforemntioned book, we have already built and tested all the components of the virtual computer, starting form its hardware design (written in HDL) all the way to its simplistic OS (written in the simple high level language Jack). The abstractions we built include an assembler, a virtual machine translator, and a compiler. 

  For example, consider a simple program that reads two integers from the user and outputs their sum. How does the computer know to read and interpret user inputs, with what protocol does it communicate with the keyboard? How then does it turn the inputs into integers, and perform mathematical operations on them? Finally, how does it know to correctly display the output on the screen? Our application hopes to demystify the chain of events that make such simple (and taken for granted) operations possible. Our application will feel like following the electric signal emitted by simple key strokes through all the phsyical and software components it passes through, till it is finally turned into a sensible screen output. All the black boxes, and abstractions therein, will be unboxed and made clear through a series of easy to understand, and visually appealing, animated displays.
  
  Our application is preferable, as compared to existing debugging and inspection tools, because our virtual computer and the abstractions that ran on top of it (the assembler, the vm translator, and the compiler) are all simple enough to control and understand (we know that because we were able to build them in the span of two months). Because of this simplicity, the user will not be confused with too much detail, and because we have control of all the abstractions, we can show the user everything (including the hdl code, assembler code, the vm translator code and the compiler code) and every interaction that takes place to make the program operations possible. Such transparency, control, and simplicity is an advantage we have, something which other tools can not boast about because of the sheer complexity of the system they have to deal with, and because they simply don't have access to everything (they are boxed out of important abstractions, such as the hardware design, the assembler, the vm translator, and the compiler). 

  We are very much excited about this project, not only because we will be learning a lot in the process, but also because we know how valuable it can be to students like us who wish to get a clear and comprhensive picture of the main hardware and software abstractions that make something like a general purpose computer possible. We believe applications like this will contribute much towards bridging the gap of understanding that is prevalent in the current curriculum (mainly due to the fragmented nature of computer science and software engineering courses given in many of our universities, and also due to the vastness of the detail covered in each course). What is worse is some of the important courses required to understand the inner workings of a computer, such as compiler design (something we had to deal with, though not in its full depth, while building the virtual computer), are not even included the curriculum.

  >>> A computer system that troubleshoots failures, or malfunctions, in any of its hardware components.
  -------------------------------------------------------------------------------------

  A computer system is normally in a lock down, you can't access the hardware components directly, but only through a high level software. The implication of this reality is not so desirable. If some minor hardware component crashes, you can not interact with the software, you can't know where the defect is, and hence you are prevented from fixing it. Of course, ultimately any kind of interaction with, or management of, the hardware has to be done through a software module. So what if we can have a separate software module that has nothing to do with high level system software, but does manage and inspect, assess and trouble shoot, hardware components independently, even when the OS can't start, or the PC can not boot (the independent module can be made to work on battery). This project will be about building a web app that demonstrates the feasibility of such a system.

  >>> Emulating an AI system that can design, on-demand, a control system for executing an assignment extracted from a series of simple problem descriptions.
  ---------------------------------------------

  The AI system (all simulated in a web app) will assemble hardware components, and install necessary instructions (a program) to solve direct and simple problems parsed from formalizied situation specifications. There, of course, would have to be a simplified formal language for modelling several kinds of sensors, and I/O devices (which will mainly be memory mapped), an HDL for modelling and defining hardware components, and some formal method for depenednecy management (so that separately defined hardware modules can be assembled dynamically). There would also have to be a repository of sensors, hardware components, and I/O devices from which component dependencies can be fetched on demand, when needed, and be assembled. This will not be a full fledged system that can auto manufacture control modules for solving real world scenarios. The project rather aims to explore the possibility of auto constructed control systems for much controlled and well understood situations (otherwise it would be impossible to extract clear problem statements).  


---------------------------------------------------
---------------------------------------------------


  Our application is preferable mainly because our virtual computer and the abstractions that ran on top of it (the assembler, the vm translator, and the compiler) are simple enough to control and understand. Because of this simplicity, the user will not be confused with too much detail, and because we have control of all the abstractions, we can show the user everything (including the hdl code, assembler code, the vm translator code and the compiler code) and every interaction that takes place to make the operations possible, which something other tools can not boast about (because of the complexity they have to deal with, and because they simply don't have access to everything).

  In order to defend the idea, we will have to mention some reasons for why our application is better than some debugging tools that also show the computer state (that of the cpu, the ram, and other related components as well) through inspection. Our application is preferable mainly because 
  our virtual computer and the abstractions that ran on top of it (the assembler, the vm trans-
  lator, and the compiler) are simple enough to control and understand. Because of this simplicity,
  the user will not be confused with too much detail, and because we have control of all the abstractions, we can show the user everything (including the hdl code, assembler code, the vm translator code, and the compiler code) and every interaction that takes place to make the operations possible, which is something other tools can not boast about (because of the complexity they have to deal with, and because they simply don't have access to everything).
