# A web app that interactively probes, and demystifies, all the salient hardware and software abstractions of a running virtual computer.

Computer science and software engineering courses are, as given now, not well structured to provide students with a clear and comprehensive understanding of what a computer really is, and what essential concepts/theories it entails. Some courses are cluttered with too much detail, while others scratch only the surface. And there is no clear progression from one course to the next. Hence computer science and software engineering students often graduate without forming a lucid picture of the components that make up a computer, the interactions that take place between these components, and the underlying principles and abstractions that in turn make the interactions possible.

In this project, we aim to build a web app that visually and interactively illustrates the salient interactions and abstractions that a high level program (operation) passes through till it is turned into a machine code (of zeros and ones) that is channeled through an architecture made up of just NAND gates and flip-flops. The interactive animation will be built on top of a simplified virtual computer (as specified in the book 'The elements of computing systems from first principles') that will be running alongside the visual animations and displays.

With the guidance of the aforementioned book, we have already built and tested all the components of the virtual computer, starting from its hardware design (written in HDL) all the way to its simplistic OS (written in the simple high level language Jack). The abstractions we built include an assembler, a virtual machine translator, and a compiler. 

For example, consider a simple program that reads two integers from the user and outputs their sum. How does the computer know to read and interpret user inputs, with what protocol does it communicate with the keyboard? How then does it turn the inputs into integers, and perform mathematical operations on them? Finally, how does it know to correctly display the output on the screen? Our application hopes to demystify the chain of events that make such simple (and taken for granted) operations possible. Our application will feel like following the electric signal emitted by simple key strokes through all the physical and software components it passes through, till it is finally turned into a sensible screen output. All the black boxes and abstractions therein, will be unboxed and made clear through a series of easy to understand, and visually appealing, animated displays.

Our application is preferable, as compared to existing debugging and inspection tools; because our virtual computer and the abstractions that ran on top of it (the assembler, the VM translator, and the compiler) are all simple enough to control and understand (we know that because we were able to build them in the span of two months). Because of this simplicity, the user will not be confused with too much detail, and because we have control of all the abstractions, we can show the user everything (including the HDL code, assembler code, the VM translator code and the compiler code) and every interaction that takes place to make the program operations possible. Such transparency, control, and simplicity is an advantage we have, something which other tools cannot boast about because of the sheer complexity of the system they have to deal with, and because they simply don't have access to everything (they are boxed out of important abstractions, such as the hardware design, the assembler, the VM translator, and the compiler).

We are very much excited about this project, not only because we will be learning a lot in the process, but also because we know how valuable it can be to students like us who wish to get a clear and comprehensive picture of the main hardware and software abstractions that make something like a general purpose computer possible. We believe applications like this will contribute much towards bridging the gap of understanding that is prevalent in the current curriculum (mainly due to the fragmented nature of computer science and software engineering courses given in many of our universities, and also due to the vastness of the detail covered in each course). What is worse is some of the important courses required to understand the inner workings of a computer, such as compiler design (something we had to deal with, though not in its full depth, while building the virtual computer), are not even included the curriculum.

# A computer system that troubleshoots failures, or malfunctions, in any of its hardware components.

A computer system is normally in a lock down, you can't access the hardware components directly, but only through high level software. The implication of this reality is not so desirable. If some minor hardware component crashes, you cannot interact with the software, you can't know where the defect is, and hence you are prevented from fixing it. Of course, ultimately any kind of interaction with, or management of, the hardware has to be done through a software module. So what if we can have a separate software module that has nothing to do with high level system software, but does manage and inspect, assess and trouble shoot, hardware components independently, even when the OS can't start, or the PC cannot boot (the independent module can be made to work on battery). This project will be about building a web app that demonstrates the feasibility of such a system.

# Emulating an AI system that can design, on-demand, a control system for executing an assignment extracted from a series of simple problem descriptions.

The AI system (all simulated in a web app) will assemble hardware components, and install necessary instructions (a program) to solve direct and simple problems parsed from formalized situation specifications. There, of course, would have to be a simplified formal language for modelling several kinds of sensors, and I/O devices (which will mainly be memory mapped), an HDL for modelling and defining hardware components, and some formal method for dependency management (so that separately defined hardware modules can be assembled dynamically). There would also have to be a repository of sensors, hardware components, and I/O devices from which component dependencies can be fetched on demand, when needed, and be assembled. This will not be a full-fledged system that can auto manufacture control modules for solving real world scenarios. The project rather aims to explore the possibility of auto constructed control systems for much controlled and well understood situations (otherwise it would be impossible to extract clear problem statements).
